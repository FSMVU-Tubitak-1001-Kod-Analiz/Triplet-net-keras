{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Conv1D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(train_test_ratio):\n",
    "    X = []\n",
    "    y = []\n",
    "    X = pd.read_excel(io='CompareResult4.xlsx', sheet_name='Sheet1',usecols=\"J,K,L\")\n",
    "    X.fillna(0,inplace=True)\n",
    "    X=X.to_numpy()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_train_test_dataset(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=8396\n",
    "#x_train_flat_anchor = tf.reshape(x_train[0:,0], [data_size, 1])\n",
    "\n",
    "x_train_flat_anchor = x_train[0:,0]\n",
    "x_train_flat_positive = x_train[0:,1]\n",
    "x_train_flat_negative = x_train[0:,2]\n",
    "\n",
    "#print(x_train_flat_anchor)\n",
    "#x_test_flat = x_test.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne = TSNE()\n",
    "#train_tsne_embeds = tsne.fit_transform(x_train_flat[:512])\n",
    "#scatter(train_tsne_embeds, y_train[:512], \"Samples from Training Data\")\n",
    "\n",
    "#eval_tsne_embeds = tsne.fit_transform(x_test_flat[:512])\n",
    "#scatter(eval_tsne_embeds, y_test[:512], \"Samples from Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_input = Input((784,))\n",
    "Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "Classifier_model = Model(Classifier_input, Classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_onehot = le.fit_transform(y_train)\n",
    "#y_test_onehot = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier_model.fit(x_train_flat,y_train_onehot, validation_data=(x_test_flat,y_test_onehot),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplet():\n",
    "    x= get_train_test_dataset(0.7);  \n",
    "                \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = generate_triplet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8396, 3)\n",
      "(8396, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(1,1))) #this line\n",
    "    #model.add(Conv1D(1,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    #model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    #model.add(Conv1D(10,(1),padding='same',activation='relu',name='conv2'))\n",
    "    #model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    #model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(10,name='embeddings'))\n",
    "    # model.add(Dense(600))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30)\n",
      "(None, 30)\n"
     ]
    }
   ],
   "source": [
    "data_size=1\n",
    "anchor_input = Input((1, ), name='anchor_input')\n",
    "positive_input = Input((1, ), name='positive_input')\n",
    "negative_input = Input((1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network([1,])\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "print(merged_vector.shape)\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "#model.compile(loss=loss_fn, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor_input (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " positive_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " negative_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 10)           20          ['anchor_input[0][0]',           \n",
      "                                                                  'positive_input[0][0]',         \n",
      "                                                                  'negative_input[0][0]']         \n",
      "                                                                                                  \n",
      " merged_layer (Concatenate)     (None, 30)           0           ['sequential_3[0][0]',           \n",
      "                                                                  'sequential_3[1][0]',           \n",
      "                                                                  'sequential_3[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor_input (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " positive_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " negative_input (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 10)           20          ['anchor_input[0][0]',           \n",
      "                                                                  'positive_input[0][0]',         \n",
      "                                                                  'negative_input[0][0]']         \n",
      "                                                                                                  \n",
      " merged_layer (Concatenate)     (None, 30)           0           ['sequential_4[0][0]',           \n",
      "                                                                  'sequential_4[1][0]',           \n",
      "                                                                  'sequential_4[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8396\n",
      "8396\n",
      "8396\n",
      "8396\n"
     ]
    }
   ],
   "source": [
    "Anchor = x_train[:,0]\n",
    "Positive = x_train[:,1]\n",
    "Negative = x_train[:,2]\n",
    "Anchor_test = x_train[:,0]\n",
    "Positive_test = x_train[:,1]\n",
    "Negative_test = x_train[:,2]\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],1))\n",
    "print(Y_dummy.size)\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "print(Y_dummy2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 1, 1, 1], dtype=int64),\n",
       " array([2, 5, 5, ..., 2, 2, 2], dtype=int64),\n",
       " array([5, 5, 2, ..., 2, 2, 2], dtype=int64)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 1, 1, 1], dtype=int64),\n",
       " array([2, 5, 5, ..., 2, 2, 2], dtype=int64),\n",
       " array([5, 5, 2, ..., 2, 2, 2], dtype=int64)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Anchor,Positive,Negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "y_pred.shape =  Tensor(\"model_10/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n",
      "y_pred.shape =  Tensor(\"model_10/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n",
      "835/840 [============================>.] - ETA: 0s - loss: 0.4033y_pred.shape =  Tensor(\"model_10/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102: RuntimeWarning: overflow encountered in cast\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4033 - val_loss: 0.4033\n",
      "Epoch 2/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4033 - val_loss: 0.4032\n",
      "Epoch 3/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4032 - val_loss: 0.4032\n",
      "Epoch 4/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4032 - val_loss: 0.4032\n",
      "Epoch 5/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4032 - val_loss: 0.4031\n",
      "Epoch 6/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4031 - val_loss: 0.4031\n",
      "Epoch 7/10\n",
      "840/840 [==============================] - 1s 2ms/step - loss: 0.4031 - val_loss: 0.4031\n",
      "Epoch 8/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4031 - val_loss: 0.4030\n",
      "Epoch 9/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4030 - val_loss: 0.4030\n",
      "Epoch 10/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4030 - val_loss: 0.4030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ae3dbdc30>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "y_pred.shape =  Tensor(\"model_13/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n",
      "y_pred.shape =  Tensor(\"model_13/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n",
      "767/840 [==========================>...] - ETA: 0s - loss: 0.4054y_pred.shape =  Tensor(\"model_13/merged_layer/concat:0\", shape=(None, 30), dtype=float32)\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4050 - val_loss: 0.4049\n",
      "Epoch 2/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4049 - val_loss: 0.4049\n",
      "Epoch 3/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4049 - val_loss: 0.4049\n",
      "Epoch 4/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4049 - val_loss: 0.4048\n",
      "Epoch 5/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4048 - val_loss: 0.4048\n",
      "Epoch 6/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4048 - val_loss: 0.4047\n",
      "Epoch 7/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4047 - val_loss: 0.4047\n",
      "Epoch 8/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4047 - val_loss: 0.4047\n",
      "Epoch 9/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4047 - val_loss: 0.4046\n",
      "Epoch 10/10\n",
      "840/840 [==============================] - 1s 1ms/step - loss: 0.4046 - val_loss: 0.4046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ae0920730>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "\n",
    "    import sys\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "\n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "\n",
    "\n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)\n",
    "\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model.load_weights('triplet_model_MNIST.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ali.nizam\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE()\n",
    "X_train_trm = trained_model.predict(x_train[:512].reshape(-1,1))\n",
    "# X_test_trm = trained_model.predict(x_test[:512].reshape(-1,28,28,1))\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "# eval_tsne_embeds = tsne.fit_transform(X_test_trm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.05170216, -21.117847  ],\n",
       "       [  0.35083055,  11.7853985 ],\n",
       "       [ -0.7663615 ,   7.741275  ],\n",
       "       ...,\n",
       "       [  0.05162948, -21.134188  ],\n",
       "       [  0.17648223,   8.566288  ],\n",
       "       [ -0.55646175,   9.458549  ]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-21.036894  ,  -4.4034395 ],\n",
       "       [  9.478342  ,   2.2317417 ],\n",
       "       [  4.4925876 ,   2.7020884 ],\n",
       "       ...,\n",
       "       [-21.050306  ,  -4.4068284 ],\n",
       "       [ 10.854581  ,  -0.21599801],\n",
       "       [  8.0583    ,   3.4296262 ]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tsne_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter(train_tsne_embeds, y_train[:512], \"Training Data After TNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter(eval_tsne_embeds, y_test[:512], \"Validation Data After TNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_trm = trained_model.predict(x_train.reshape(-1,28,28,1))\n",
    "# X_test_trm = trained_model.predict(x_test.reshape(-1,28,28,1))\n",
    "#\n",
    "# Classifier_input = Input((4,))\n",
    "# Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "# Classifier_model = Model(Classifier_input, Classifier_output)\n",
    "#\n",
    "#\n",
    "# Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#\n",
    "# Classifier_model.fit(X_train_trm,y_train_onehot, validation_data=(X_test_trm,y_test_onehot),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
