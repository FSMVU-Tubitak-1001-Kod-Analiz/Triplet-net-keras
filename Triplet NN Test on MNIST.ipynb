{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "95    14.0\n",
       "96    14.0\n",
       "97    14.0\n",
       "98    14.0\n",
       "99    14.0\n",
       "Name: smellKey_encoded, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Data/sub_dataset_list.pkl', 'rb') as f:\n",
    "    smellKey_list = pickle.load(f)\n",
    "smellKey_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_data = pd.Series(np.arange(0, 2500, dtype=np.float64))\n",
    "for i in range(len(series_data)):\n",
    "  if i < 500:\n",
    "    series_data[i] = 0\n",
    "  elif i < 1000:\n",
    "    series_data[i] = 1\n",
    "  elif i < 1500:\n",
    "    series_data[i] = 2\n",
    "  elif i < 2000:\n",
    "    series_data[i] = 3\n",
    "  else:\n",
    "    series_data[i] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'Data/2500_Smell.pt'\n",
    "loaded_ast_embeddings = torch.load(save_path)\n",
    "loaded_ast_embeddings = loaded_ast_embeddings.numpy()\n",
    "loaded_ast_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'fn_smell_embeddings.pt': loaded_ast_embeddings.tolist(),\n",
    "    'smellKey_encoded': series_data\n",
    "})\n",
    "\n",
    "X = np.array(data['fn_smell_embeddings.pt'].tolist())\n",
    "y = np.array(data['smellKey_encoded'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21949668,  0.52009624,  0.80027395, ..., -0.39148009,\n",
       "        -0.59952378,  0.4945178 ],\n",
       "       [ 0.06018562,  0.44275349,  1.07437146, ..., -0.35398841,\n",
       "        -0.79761583,  0.55565304],\n",
       "       [ 0.08509637,  0.29572806,  0.819547  , ..., -0.53149134,\n",
       "        -0.31133565,  0.34643734],\n",
       "       ...,\n",
       "       [ 0.07617371, -0.2423819 ,  1.13228214, ..., -0.39075366,\n",
       "        -0.55751336,  0.64451575],\n",
       "       [-0.15223742,  0.35884848, -0.09361228, ..., -0.59589565,\n",
       "        -0.35234824,  0.83614349],\n",
       "       [-0.04150327,  0.43444666,  0.55787909, ..., -0.32020199,\n",
       "        -0.41934377,  0.42905429]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, labels, subtitle=None):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[labels == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 768)\n",
      "(2000, 768)\n"
     ]
    }
   ],
   "source": [
    "x_train_flat = x_train\n",
    "x_test_flat = x_test\n",
    "print(x_train.shape)\n",
    "print(x_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(x_train[:512])\n",
    "scatter(train_tsne_embeds, y_train[:512], \"Samples from Training Data\")\n",
    "\n",
    "eval_tsne_embeds = tsne.fit_transform(x_test[:512])\n",
    "scatter(eval_tsne_embeds, y_test[:512], \"Samples from Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier_input = Input((768,))\n",
    "# Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "# Classifier_model = Model(Classifier_input, Classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_model = Sequential()\n",
    "Classifier_model.add(Dense(350 , input_shape=(768,), activation='relu'))\n",
    "Classifier_model.add(Dense(50,activation='relu'))\n",
    "Classifier_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = le.fit_transform(y_train)\n",
    "y_test_onehot = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 1.0468 - accuracy: 0.5890 - val_loss: 0.8243 - val_accuracy: 0.6840\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7150 - val_loss: 0.6538 - val_accuracy: 0.7460\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7790 - val_loss: 0.5489 - val_accuracy: 0.7920\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.8225 - val_loss: 0.5188 - val_accuracy: 0.8180\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.8300 - val_loss: 0.4974 - val_accuracy: 0.8280\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.5430 - val_accuracy: 0.7780\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8585 - val_loss: 0.6143 - val_accuracy: 0.7680\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.4306 - val_accuracy: 0.8460\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8990 - val_loss: 0.4446 - val_accuracy: 0.8360\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9030 - val_loss: 0.4977 - val_accuracy: 0.8320\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2299 - accuracy: 0.9130 - val_loss: 0.4806 - val_accuracy: 0.8280\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9155 - val_loss: 0.4449 - val_accuracy: 0.8440\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9375 - val_loss: 0.4589 - val_accuracy: 0.8360\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9425 - val_loss: 0.4980 - val_accuracy: 0.8300\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9605 - val_loss: 0.5493 - val_accuracy: 0.8380\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9675 - val_loss: 0.5920 - val_accuracy: 0.8200\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9685 - val_loss: 0.4867 - val_accuracy: 0.8560\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9685 - val_loss: 0.5296 - val_accuracy: 0.8220\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9760 - val_loss: 0.5203 - val_accuracy: 0.8240\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9760 - val_loss: 0.5301 - val_accuracy: 0.8560\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9825 - val_loss: 0.5517 - val_accuracy: 0.8460\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9845 - val_loss: 0.6195 - val_accuracy: 0.8380\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9875 - val_loss: 0.6140 - val_accuracy: 0.8400\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9835 - val_loss: 0.5780 - val_accuracy: 0.8520\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 0.5736 - val_accuracy: 0.8500\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.5807 - val_accuracy: 0.8380\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9530 - val_loss: 0.5791 - val_accuracy: 0.8460\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9765 - val_loss: 0.6689 - val_accuracy: 0.8380\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.7269 - val_accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.7058 - val_accuracy: 0.8300\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9670 - val_loss: 0.5711 - val_accuracy: 0.8420\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9820 - val_loss: 0.6389 - val_accuracy: 0.8300\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.6864 - val_accuracy: 0.8420\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.6273 - val_accuracy: 0.8380\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 0.6348 - val_accuracy: 0.8700\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.7351 - val_accuracy: 0.8260\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.7510 - val_accuracy: 0.8420\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.7404 - val_accuracy: 0.8220\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.9903 - val_accuracy: 0.8180\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 1.0449 - val_accuracy: 0.7900\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9790 - val_loss: 0.7561 - val_accuracy: 0.8300\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.6974 - val_accuracy: 0.8260\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.6965 - val_accuracy: 0.8380\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.7861 - val_accuracy: 0.8340\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.7358 - val_accuracy: 0.8520\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 0.7792 - val_accuracy: 0.8360\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9905 - val_loss: 0.6860 - val_accuracy: 0.8520\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.7645 - val_accuracy: 0.8260\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9850 - val_loss: 0.8474 - val_accuracy: 0.8300\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9570 - val_loss: 0.9970 - val_accuracy: 0.7820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee7fabd810>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier_model.fit(x_train_flat,y_train_onehot, validation_data=(x_test_flat,y_test_onehot),epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplet(x,y,testsize=0.3,ap_pairs=10,an_pairs=10):\n",
    "    data_xy = tuple([x,y])\n",
    "\n",
    "    trainsize = 1-testsize\n",
    "\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "\n",
    "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "        A_P_pairs = random.sample(list(permutations(same_class_idx,2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),k=an_pairs)\n",
    "        \n",
    "\n",
    "        #train\n",
    "        A_P_len = len(A_P_pairs)\n",
    "        Neg_len = len(Neg_idx)\n",
    "        for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])               \n",
    "        #test\n",
    "        for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])    \n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 3, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = generate_triplet(x_train_flat,y_train, ap_pairs=150, an_pairs=150,testsize=0.2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network():\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(768,1)))\n",
    "    # model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    # model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    # model.add(Conv2D(256,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    # model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    # model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(768,name='embeddings'))\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = Input((768,1), name='anchor_input')\n",
    "positive_input = Input((768,1 ), name='positive_input')\n",
    "negative_input = Input((768,1 ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network()\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor_input (InputLayer)      [(None, 768, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " positive_input (InputLayer)    [(None, 768, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " negative_input (InputLayer)    [(None, 768, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 768)          590592      ['anchor_input[0][0]',           \n",
      "                                                                  'positive_input[0][0]',         \n",
      "                                                                  'negative_input[0][0]']         \n",
      "                                                                                                  \n",
      " merged_layer (Concatenate)     (None, 2304)         0           ['sequential_3[0][0]',           \n",
      "                                                                  'sequential_3[1][0]',           \n",
      "                                                                  'sequential_3[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 590,592\n",
      "Trainable params: 590,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 3, 768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "y_pred.shape =  Tensor(\"model_1/merged_layer/concat:0\", shape=(None, 2304), dtype=float32)\n",
      "y_pred.shape =  Tensor(\"model_1/merged_layer/concat:0\", shape=(None, 2304), dtype=float32)\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.4392y_pred.shape =  Tensor(\"model_1/merged_layer/concat:0\", shape=(None, 2304), dtype=float32)\n",
      "176/176 [==============================] - 9s 44ms/step - loss: 0.4374 - val_loss: 2.8371\n",
      "Epoch 2/500\n",
      "127/176 [====================>.........] - ETA: 1s - loss: 0.0150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\omerkerem.adali\\Desktop\\tubitak\\Triplet-net-keras\\Triplet NN Test on MNIST.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/omerkerem.adali/Desktop/tubitak/Triplet-net-keras/Triplet%20NN%20Test%20on%20MNIST.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m Y_dummy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(( Anchor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m300\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/omerkerem.adali/Desktop/tubitak/Triplet-net-keras/Triplet%20NN%20Test%20on%20MNIST.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m Y_dummy2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((Anchor_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/omerkerem.adali/Desktop/tubitak/Triplet-net-keras/Triplet%20NN%20Test%20on%20MNIST.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit([Anchor,Positive,Negative],y\u001b[39m=\u001b[39;49mY_dummy,validation_data\u001b[39m=\u001b[39;49m([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\omerkerem.adali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Anchor = X_train[:,0,:].reshape(-1,768,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,768,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,768,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,768,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,768,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,768,1)\n",
    "\n",
    "Y_dummy = np.empty(( Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=512, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 768, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ready_data = loaded_ast_embeddings.reshape(-1,768,1)\n",
    "predict_ready_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictedModel = model.predict([predict_ready_data, predict_ready_data, predict_ready_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2304)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedModel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputAnchor = predictedModel[:, :768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputAnchor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputAnchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(outputAnchor, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0345 - accuracy: 0.9750 - val_loss: 1.6808 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 1.6705 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - accuracy: 0.9875 - val_loss: 1.6911 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 0.9875 - val_loss: 1.7141 - val_accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 1.7167 - val_accuracy: 0.4500\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0280 - accuracy: 0.9875 - val_loss: 1.7543 - val_accuracy: 0.4500\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 1.7393 - val_accuracy: 0.4500\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 1.7155 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0274 - accuracy: 0.9875 - val_loss: 1.7064 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0293 - accuracy: 0.9750 - val_loss: 1.7047 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0287 - accuracy: 0.9875 - val_loss: 1.7169 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9875 - val_loss: 1.7335 - val_accuracy: 0.4500\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 0.9875 - val_loss: 1.7294 - val_accuracy: 0.4500\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0232 - accuracy: 0.9875 - val_loss: 1.6908 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 1.6896 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 1.7086 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9750 - val_loss: 1.7481 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0287 - accuracy: 0.9750 - val_loss: 1.7455 - val_accuracy: 0.4500\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0247 - accuracy: 0.9875 - val_loss: 1.7611 - val_accuracy: 0.4500\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0281 - accuracy: 0.9875 - val_loss: 1.7537 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0257 - accuracy: 0.9875 - val_loss: 1.7333 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9875 - val_loss: 1.7250 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9875 - val_loss: 1.7376 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0234 - accuracy: 0.9875 - val_loss: 1.7787 - val_accuracy: 0.4500\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0287 - accuracy: 0.9875 - val_loss: 1.7797 - val_accuracy: 0.4500\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 1.7466 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0283 - accuracy: 0.9750 - val_loss: 1.7303 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0289 - accuracy: 0.9875 - val_loss: 1.7394 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0250 - accuracy: 0.9875 - val_loss: 1.7609 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 1.8128 - val_accuracy: 0.4500\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 0.9875 - val_loss: 1.7625 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0238 - accuracy: 0.9875 - val_loss: 1.7481 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 1.7514 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 1.7759 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 0.9875 - val_loss: 1.7885 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9875 - val_loss: 1.7780 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9750 - val_loss: 1.7554 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9875 - val_loss: 1.7592 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0245 - accuracy: 0.9875 - val_loss: 1.7722 - val_accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9875 - val_loss: 1.7897 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9875 - val_loss: 1.7835 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9875 - val_loss: 1.7861 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9875 - val_loss: 1.7955 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 0.9875 - val_loss: 1.7977 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9875 - val_loss: 1.8123 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9875 - val_loss: 1.8406 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 0.9875 - val_loss: 1.8215 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9875 - val_loss: 1.7946 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9875 - val_loss: 1.7958 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 1.8062 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db1307c4f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier_model.fit(x_train_flat,y_train_onehot, validation_data=(x_test_flat,y_test_onehot),epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
